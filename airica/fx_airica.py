# import toolbox
import pandas as pd
import numpy as np
from matplotlib import dates as mdates

def process_airica(crm_val, xlsx_filepath, dbs_filepath,
                   results_file_path_and_name):
    # import ".xlsx" file
    db = pd.read_excel(xlsx_filepath, skiprows=[1])
    L = db.flag == 2
    db = db[L]
    db = db.reset_index()
    
    # extract data from dbs
    mapper_dbs = {
    "run type": "run_type",
    "i.s. temp.": "temperature_insitu",
    "sample mass": "mass_sample",
    "rep#": "rep",
    "CT": "dic",
    "factor CT": "dic_factor",
    "CV (Âµmol)": "cv_micromol",
    "CV (%)": "cv_percent",
    "last CRM CT": "lastcrm_dic_measured",
    "cert. CRM CT": "lastcrm_dic_certified",
    "CRM batch": "lastcrm_batch",
    "calc. mode": "mode_calculation",
    "integ. mode": "mode_integration",
    "Lat.": "latitude",
    "Long.": "longitude",
    "area#1": "area_1",
    "area#2": "area_2",
    "area#3": "area_3",
    "area#4": "area_4",
}

    def read_dbs(filepath_or_buffer, encoding="unicode_escape", na_values="none", **kwargs):
        """Import the dbs file generated by a Marianda AIRICA as a pandas DataFrame.
        All kwargs are passed to pandas.read_table.
        """
        dbs = pd.read_table(
            filepath_or_buffer, encoding=encoding, na_values=na_values, **kwargs
        )
        dbs.rename(mapper=mapper_dbs, axis=1, inplace=True)
        dbs.drop(columns="Unnamed: 32", inplace=True)
        dbs["datetime"] = pd.to_datetime(
            dbs.apply(lambda x: " ".join((x.date, x.time)), axis=1)
        )
        dbs["datenum"] = mdates.date2num(dbs.datetime)
        return dbs

    # import ".dbs" file
    data = read_dbs(dbs_filepath)
    
    # add ".dbs" data to ".xlsx"
    sample_list = db["name"].tolist()
    
    db.loc[db["name"]==sample_list, "temperature"] = data.temperature
    db.loc[db["name"]==sample_list, "salinity"] = data.salinity
    db.loc[db["name"]==sample_list, "density"] = data.density
    db.loc[db["name"]==sample_list, "mass_sample"] = data.mass_sample
    db.loc[db["name"]==sample_list, "time"] = data.time
    db.loc[db["name"]==sample_list, "area_1"] = data.area_1
    db.loc[db["name"]==sample_list, "area_2"] = data.area_2
    db.loc[db["name"]==sample_list, "area_3"] = data.area_3
    db.loc[db["name"]==sample_list, "area_4"] = data.area_4
    db.loc[db["name"]==sample_list, "bottle"] = data.bottle
    
    # check that ".dbs" bottle = ".xlsx" name and drop "bottle" column
    if db["name"].equals(db["bottle"]):
        print("SUCCESSFUL DBS IMPORT")
        db = db.drop(columns=["bottle"])
    else:
        KeyError
        print("ERROR: mismatch between dbs and xlsx files")
    
    # average areas with all areas and only last 3 areas
    db["area_av_4"] = (db.area_1+db.area_2+db.area_3+db.area_4)/4
    db["area_av_3"] = (db.area_1+db.area_2+db.area_3)/3
    
    # create columns to hold conversion factor (CF) values
    db["CF_3"] = np.nan
    db["CF_4"] = np.nan
    
    # calc CRM coeff factor
    def get_CF(db):
        """ Calculate conversion factor CF for each analysis batch."""
        db.CF_3 = (crm_val*db.density*db.sample_v)/db.area_av_3
        db.CF_4 = (crm_val*db.density*db.sample_v)/db.area_av_4
        CF_3f = db.loc[db["location"] == "CRM", "CF_3"].mean()
        CF_4f = db.loc[db["location"] == "CRM", "CF_4"].mean()
        return pd.Series({
        "CF_3f": CF_3f,
        "CF_4f": CF_4f,
        })
    
    db_cf = db.groupby(by=["analysis_batch"]).apply(get_CF)
    
    # assign a CRM CF to samples based on analysis batch
    db["CF_3"] = db_cf.loc[db.analysis_batch.values, 'CF_3f'].values
    db["CF_4"] = db_cf.loc[db.analysis_batch.values, 'CF_4f'].values
    
    # calculate TCO2 values
    db["TCO2_3"] = np.nan
    db["TCO2_4"] = np.nan
    
    db["TCO2_3"] = (db.CF_3*db.area_av_3)/(db.density*db.sample_v)
    db["TCO2_4"] = (db.CF_4*db.area_av_4)/(db.density*db.sample_v)
    
    # save results as text file
    db.to_csv(results_file_path_and_name, index=None)
